{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "169g5NuucK2wNJXFvLqi-tlCc3sWoHEug",
      "authorship_tag": "ABX9TyOsXtiVmTSftCQWhC/cGtn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wuyi010/model/blob/main/resnet34%5C50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dube4JbkeE5W",
        "outputId": "8f413c23-889c-4f66-e555-dc10d93c3cf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Pytorch官方ResNet模型\\nfrom torchvision.models import resnet34\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "# 搭建resnet-layer模型\n",
        "#\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torchvision.models.resnet\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"搭建BasicBlock模块\"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 使用BN层是不需要使用bias的，bias最后会抵消掉\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)    # BN层, BN层放在conv层和relu层中间使用\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        identity = X\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "\n",
        "        if self.downsample is not None:    # 保证原始输入X的size与主分支卷积后的输出size叠加时维度相同\n",
        "            identity = self.downsample(X)\n",
        "\n",
        "        return self.relu(Y + identity)\n",
        "        \"\"\"神经网络的前向传播函数:\n",
        "            它接受一个输入张量X，然后通过一些卷积层和批量归一化层来计算输出张量Y。\n",
        "            如果存在下采样层，它将对输入张量进行下采样以使其与输出张量的尺寸相同。\n",
        "            最后，输出张量Y和输入张量X的恒等映射相加并通过ReLU激活函数进行激活。\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    \"\"\"搭建BottleNeck模块\"\"\"\n",
        "    # BottleNeck模块最终输出out_channel是Residual模块输入in_channel的size的4倍(Residual模块输入为64)，shortcut分支in_channel\n",
        "    # 为Residual的输入64，因此需要在shortcut分支上将Residual模块的in_channel扩张4倍，使之与原始输入图片X的size一致\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        # 默认原始输入为224，经过7x7层和3x3层之后BottleNeck的输入降至64\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)    # BN层, BN层放在conv层和relu层中间使用\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(out_channel, out_channel * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)  # Residual中第三层out_channel扩张到in_channel的4倍\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        identity = X\n",
        "\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "\n",
        "        if self.downsample is not None:    # 保证原始输入X的size与主分支卷积后的输出size叠加时维度相同\n",
        "            identity = self.downsample(X)\n",
        "\n",
        "        return self.relu(Y + identity)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"搭建ResNet-layer通用框架\"\"\"\n",
        "    # num_classes是训练集的分类个数，include_top是在ResNet的基础上搭建更加复杂的网络时用到，此处用不到\n",
        "    def __init__(self, residual, num_residuals, num_classes=1000, include_top=True):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.out_channel = 64    # 输出通道数(即卷积核个数)，会生成与设定的输出通道数相同的卷积核个数\n",
        "        self.include_top = include_top\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.out_channel, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)    # 3表示输入特征图像的RGB通道数为3，即图片数据的输入通道为3\n",
        "        self.bn1 = nn.BatchNorm2d(self.out_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = self.residual_block(residual, 64, num_residuals[0])\n",
        "        self.conv3 = self.residual_block(residual, 128, num_residuals[1], stride=2)\n",
        "        self.conv4 = self.residual_block(residual, 256, num_residuals[2], stride=2)\n",
        "        self.conv5 = self.residual_block(residual, 512, num_residuals[3], stride=2)\n",
        "        if self.include_top:\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))    # output_size = (1, 1)\n",
        "            self.fc = nn.Linear(512 * residual.expansion, num_classes)\n",
        "\n",
        "        # 对conv层进行初始化操作\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #fan_out保留了向后传递中权重的大小。\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def residual_block(self, residual, channel, num_residuals, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        # 用在每个conv_x组块的第一层的shortcut分支上，此时上个conv_x输出out_channel与本conv_x所要求的输入in_channel通道数不同，\n",
        "        # 所以用downsample调整进行升维，使输出out_channel调整到本conv_x后续处理所要求的维度。\n",
        "        # 同时stride=2进行下采样减小尺寸size，(注：conv2时没有进行下采样，conv3-5进行下采样，size=56、28、14、7)。\n",
        "        if stride != 1 or self.out_channel != channel * residual.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.out_channel, channel * residual.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * residual.expansion))\n",
        "\n",
        "        block = []    # block列表保存某个conv_x组块里for循环生成的所有层\n",
        "        # 添加每一个conv_x组块里的第一层，第一层决定此组块是否需要下采样(后续层不需要)\n",
        "        block.append(residual(self.out_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.out_channel = channel * residual.expansion    # 输出通道out_channel扩张\n",
        "\n",
        "        for _ in range(1, num_residuals):\n",
        "            block.append(residual(self.out_channel, channel))\n",
        "\n",
        "        # 非关键字参数的特征是一个星号*加上参数名，比如*number，定义后，number可以接收任意数量的参数，并将它们储存在一个tuple中\n",
        "        return nn.Sequential(*block)\n",
        "\n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.maxpool(Y)\n",
        "        Y = self.conv5(self.conv4(self.conv3(self.conv2(Y))))\n",
        "\n",
        "        if self.include_top:\n",
        "            Y = self.avgpool(Y)\n",
        "            Y = torch.flatten(Y, 1)\n",
        "            Y = self.fc(Y)\n",
        "\n",
        "        return Y\n",
        "\n",
        "\n",
        "# 构建ResNet-34模型\n",
        "def resnet34(num_classes=1000, include_top=True):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
        "\n",
        "\n",
        "# 构建ResNet-50模型\n",
        "def resnet50(num_classes=1000, include_top=True):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
        "\n",
        "\n",
        "# 模型网络结构可视化\n",
        "net = resnet34()\n",
        "#print(net)\n",
        "\n",
        "\"\"\"\n",
        "# 1. 使用torchsummary中的summary查看模型的输入输出形状、顺序结构，网络参数量，网络模型大小等信息\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = net.to(device)\n",
        "summary(model, (3, 224, 224))    # 3是RGB通道数，即表示输入224 * 224的3通道的数据\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# 2. 使用torchviz中的make_dot生成模型的网络结构，pdf图包括计算路径、网络各层的权重、偏移量\n",
        "from torchviz import make_dot\n",
        "\n",
        "X = torch.rand(size=(1, 3, 224, 224))    # 3是RGB通道数，即表示输入224 * 224的3通道的数据\n",
        "Y = net(X)\n",
        "vise = make_dot(Y, params=dict(net.named_parameters()))\n",
        "vise.view()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Pytorch官方ResNet模型\n",
        "from torchvision.models import resnet34\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3N99S99nvF40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#迁移学习\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "#from model import resnet34\n",
        "import torchvision.models.resnet\n",
        "#from model import resnet34\n",
        "#import torchvision.models.resnet34\n",
        "\n",
        "#基于迁移学习方法使用少量epoch即可达到很高的准确率\n",
        "\n",
        "#加载和预处理数据集：\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} device.\".format(device))\n",
        "data_transform = {\n",
        "  \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                   transforms.RandomHorizontalFlip(),\n",
        "                   transforms.ToTensor(),\n",
        "                   transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])]),\n",
        "   \"val\": transforms.Compose([transforms.Resize(256),#将图片最小边缩短为256\n",
        "                  transforms.CenterCrop(224),#再使用中心裁剪裁剪为224\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                             [0.229, 0.224, 0.225])])}\n",
        "data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
        "# image_path = os.path.join(data_root, \"data_set\", \"flower_data\")  # flower data set path\n",
        "image_path = data_root + \"data_set/flower_data\")  # flower data set path\n",
        "\n",
        "assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n",
        "                    transform=data_transform[\"train\"])\n",
        "\n",
        "\n",
        "train_num = len(train_dataset)\n",
        "# {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
        "flower_list = train_dataset.class_to_idx\n",
        "cla_dict = dict((val, key) for key, val in flower_list.items())\n",
        "# write dict into json file\n",
        "json_str = json.dumps(cla_dict, indent=4)\n",
        "with open('class_indices.json', 'w') as json_file:\n",
        "    json_file.write(json_str)\n",
        "\n",
        "batch_size = 16\n",
        "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
        "print('Using {} dataloader workers every process'.format(0))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                      batch_size=batch_size, \n",
        "                      shuffle=True,\n",
        "                      num_workers=4)\n",
        "validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n",
        "                     transform=data_transform[\"val\"])\n",
        "val_num = len(validate_dataset)\n",
        "validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
        "                        batch_size=batch_size, \n",
        "                        shuffle=False,\n",
        "                        num_workers=4)\n",
        "print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n",
        "\n",
        "\n",
        "net = resnet34()#实例化resnet34 \n",
        "# load pretrain weights\n",
        "# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
        "model_weight_path = \"./resnet34-333f7ec4.pth\"\n",
        "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
        "net.load_state_dict(torch.load(model_weight_path, map_location=device))#载入模型权重\n",
        "# for param in net.parameters():\n",
        "#     param.requires_grad = False\n",
        "# change fc layer structure\n",
        "in_channel = net.fc.in_features   #net.fc代表定义网络结构时的fc\n",
        "net.fc = nn.Linear(in_channel, 5)  #重新定义分类个数，结合数据集改动\n",
        "net.to(device)\n",
        "# define loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# construct an optimizer\n",
        "params = [p for p in net.parameters() if p.requires_grad]\n",
        "optimizer = optim.Adam(params, lr=0.0001)\n",
        "epochs = 3\n",
        "best_acc = 0.0\n",
        "save_path = './resNet34.pth'\n",
        "train_steps = len(train_loader)\n",
        "for epoch in range(epochs):\n",
        "    # train\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    train_bar = tqdm(train_loader)\n",
        "    for step, data in enumerate(train_bar):\n",
        "        images, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        logits = net(images.to(device))\n",
        "        loss = loss_function(logits, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
        "                                                                 epochs,\n",
        "                                                                 loss)\n",
        "    # validate\n",
        "    net.eval()\n",
        "    acc = 0.0                        # accumulate accurate number / epoch\n",
        "    with torch.no_grad():\n",
        "        val_bar = tqdm(validate_loader)\n",
        "        for val_data in val_bar:\n",
        "            val_images, val_labels = val_data\n",
        "            outputs = net(val_images.to(device))\n",
        "            # loss = loss_function(outputs, test_labels)\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,\n",
        "                                                       epochs)\n",
        "    val_accurate = acc / val_num\n",
        "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
        "          (epoch + 1, running_loss / train_steps, val_accurate))\n",
        "    if val_accurate > best_acc:\n",
        "        best_acc = val_accurate\n",
        "        torch.save(net.state_dict(), save_path)\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Kt6CPODt37MD",
        "outputId": "9b68bcd7-b934-4288-8b00-62bc9424f576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    transform=data_transform[\"val\"])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "训练resnet34 + CIFAR10数据集\n",
        "# 搭建resnet-layer模型\n",
        "#\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torchvision.models.resnet\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"搭建BasicBlock模块\"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # 使用BN层是不需要使用bias的，bias最后会抵消掉\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)    # BN层, BN层放在conv层和relu层中间使用\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        identity = X\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "\n",
        "        if self.downsample is not None:    # 保证原始输入X的size与主分支卷积后的输出size叠加时维度相同\n",
        "            identity = self.downsample(X)\n",
        "\n",
        "        return self.relu(Y + identity)\n",
        "        \"\"\"神经网络的前向传播函数:\n",
        "            它接受一个输入张量X，然后通过一些卷积层和批量归一化层来计算输出张量Y。\n",
        "            如果存在下采样层，它将对输入张量进行下采样以使其与输出张量的尺寸相同。\n",
        "            最后，输出张量Y和输入张量X的恒等映射相加并通过ReLU激活函数进行激活。\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    \"\"\"搭建BottleNeck模块\"\"\"\n",
        "    # BottleNeck模块最终输出out_channel是Residual模块输入in_channel的size的4倍(Residual模块输入为64)，shortcut分支in_channel\n",
        "    # 为Residual的输入64，因此需要在shortcut分支上将Residual模块的in_channel扩张4倍，使之与原始输入图片X的size一致\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        # 默认原始输入为224，经过7x7层和3x3层之后BottleNeck的输入降至64\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)    # BN层, BN层放在conv层和relu层中间使用\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(out_channel, out_channel * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)  # Residual中第三层out_channel扩张到in_channel的4倍\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        identity = X\n",
        "\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.relu(self.bn2(self.conv2(Y)))\n",
        "        Y = self.bn3(self.conv3(Y))\n",
        "\n",
        "        if self.downsample is not None:    # 保证原始输入X的size与主分支卷积后的输出size叠加时维度相同\n",
        "            identity = self.downsample(X)\n",
        "\n",
        "        return self.relu(Y + identity)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"搭建ResNet-layer通用框架\"\"\"\n",
        "    # num_classes是训练集的分类个数，include_top是在ResNet的基础上搭建更加复杂的网络时用到，此处用不到\n",
        "    def __init__(self, residual, num_residuals, num_classes=1000, include_top=True):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.out_channel = 64    # 输出通道数(即卷积核个数)，会生成与设定的输出通道数相同的卷积核个数\n",
        "        self.include_top = include_top\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.out_channel, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)    # 3表示输入特征图像的RGB通道数为3，即图片数据的输入通道为3\n",
        "        self.bn1 = nn.BatchNorm2d(self.out_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = self.residual_block(residual, 64, num_residuals[0])\n",
        "        self.conv3 = self.residual_block(residual, 128, num_residuals[1], stride=2)\n",
        "        self.conv4 = self.residual_block(residual, 256, num_residuals[2], stride=2)\n",
        "        self.conv5 = self.residual_block(residual, 512, num_residuals[3], stride=2)\n",
        "        if self.include_top:\n",
        "            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))    # output_size = (1, 1)\n",
        "            self.fc = nn.Linear(512 * residual.expansion, num_classes)\n",
        "\n",
        "        # 对conv层进行初始化操作\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') #fan_out保留了向后传递中权重的大小。\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def residual_block(self, residual, channel, num_residuals, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        # 用在每个conv_x组块的第一层的shortcut分支上，此时上个conv_x输出out_channel与本conv_x所要求的输入in_channel通道数不同，\n",
        "        # 所以用downsample调整进行升维，使输出out_channel调整到本conv_x后续处理所要求的维度。\n",
        "        # 同时stride=2进行下采样减小尺寸size，(注：conv2时没有进行下采样，conv3-5进行下采样，size=56、28、14、7)。\n",
        "        if stride != 1 or self.out_channel != channel * residual.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.out_channel, channel * residual.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * residual.expansion))\n",
        "\n",
        "        block = []    # block列表保存某个conv_x组块里for循环生成的所有层\n",
        "        # 添加每一个conv_x组块里的第一层，第一层决定此组块是否需要下采样(后续层不需要)\n",
        "        block.append(residual(self.out_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.out_channel = channel * residual.expansion    # 输出通道out_channel扩张\n",
        "\n",
        "        for _ in range(1, num_residuals):\n",
        "            block.append(residual(self.out_channel, channel))\n",
        "\n",
        "        # 非关键字参数的特征是一个星号*加上参数名，比如*number，定义后，number可以接收任意数量的参数，并将它们储存在一个tuple中\n",
        "        return nn.Sequential(*block)\n",
        "\n",
        "    # 前向传播\n",
        "    def forward(self, X):\n",
        "        Y = self.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.maxpool(Y)\n",
        "        Y = self.conv5(self.conv4(self.conv3(self.conv2(Y))))\n",
        "\n",
        "        if self.include_top:\n",
        "            Y = self.avgpool(Y)\n",
        "            Y = torch.flatten(Y, 1)\n",
        "            Y = self.fc(Y)\n",
        "\n",
        "        return Y\n",
        "\n",
        "\n",
        "# 构建ResNet-34模型\n",
        "def resnet34(num_classes=1000, include_top=True):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn,optim,tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import  make_grid\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "\n",
        "#全局变量\n",
        "batch_size=256   #每次喂入的数据量\n",
        "\n",
        "# num_print=int(50000//batch_size//4)\n",
        "num_print=100\n",
        "\n",
        "epoch_num=70 #总迭代次数\n",
        "\n",
        "lr=0.01\n",
        "step_size=10  #每n次epoch更新一次学习率\n",
        "\n",
        "#数据获取(数据增强,归一化)\n",
        "def transforms_RandomHorizontalFlip():\n",
        "\n",
        "    #transforms.Compose(),将一系列的transforms有序组合,实现按照这些方法依次对图像操作\n",
        "\n",
        "    #ToTensor()使图片数据转换为tensor张量,这个过程包含了归一化,图像数据从0~255压缩到0~1,这个函数必须在Normalize之前使用\n",
        "    #实现原理,即针对不同类型进行处理,原理即各值除以255,\n",
        "    #最后通过torch.from_numpy将PIL Image或者 numpy.ndarray()针对具体类型转成torch.tensor()数据类型\n",
        "\n",
        "    #Normalize()是归一化过程,ToTensor()的作用是将图像数据转换为(0,1)之间的张量,Normalize()则使用公式(x-mean)/std\n",
        "    #将每个元素分布到(-1,1). 归一化后数据转为标准格式,\n",
        "    transform_train=transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\n",
        "\n",
        "\n",
        "    transform=transforms.Compose([transforms.ToTensor(),\n",
        "                   transforms.Normalize((0.485,0.456,0.406),(0.226,0.224,0.225))])\n",
        "\n",
        "\n",
        "    #root:cifar-10 的根目录,data_path\n",
        "    #train:True=训练集, False=测试集\n",
        "    #transform:(可调用,可选)-接收PIL图像并返回转换版本的函数\n",
        "    #download:true=从互联网上下载数据,并将其放在root目录下,如果数据集已经下载,就什么都不干\n",
        "    train_dataset=datasets.CIFAR10(root='../../data_hub/cifar10/data_1',train=True,transform=transform_train,download=True)\n",
        "    test_dataset=datasets.CIFAR10(root='../../data_hub/cifar10/data_1',train=False,transform=transform,download=True)\n",
        "\n",
        "    return train_dataset,test_dataset\n",
        "\n",
        "#数据增强:随机翻转\n",
        "train_dataset,test_dataset=transforms_RandomHorizontalFlip()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#Dataloader(....)\n",
        "dataset:就是pytorch已有的数据读取接口,或者自定义的数据接口的输出,该输出要么是torch.utils.data.Dataset类的对象,\n",
        "要么是继承自torch.utils.data.Dataset类的自定义类的对象\n",
        "\n",
        "batch_size:如果有50000张训练集,则相当于把训练集平均分成(50000/batch_size)份,每份batch_size张图片\n",
        "train_loader中的每个元素相当于一个分组,一个组中batch_size图片,\n",
        "\n",
        "shuffle:设置为True时会在每个epoch重新打乱数据(默认:False),一般在训练数据中会采用\n",
        "num_workers:这个参数必须>=0,0的话表示数据导入在主进程中进行,其他大于0的数表示通过多个进程来导入数据,可以加快数据导入速度\n",
        "drop_last:设定为True如果数据集大小不能被批量大小整除的时候,将丢到最后一个不完整的batch(默认为False)\n",
        "'''\n",
        "\n",
        "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "#模型,优化器\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#from VggNet import *\n",
        "\n",
        "model=resnet34().to(device)\n",
        "\n",
        "#在多分类情况下一般使用交叉熵\n",
        "# torch.nn.CrossEntropyLoss相当于softmax + log + nllloss。\n",
        "# 预测的概率大于1不符合预期，可以使用softmax归一，取log后是交叉熵，取负号是为了符合loss越小，预测概率越大。\n",
        "# 在实际训练中，如果做的是分类任务，且使用CrossEntropyLoss作为损失函数的话，\n",
        "# 神经网络的部分就没必要加入nn.Softmax或者nn.LogSoftmax等之类的，因为在CrossEntropyLoss已经内置了该功能。\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "'''\n",
        "params(iterable)-待优化参数的iterable或者定义了参数组的dict\n",
        "lr(float):学习率\n",
        "\n",
        "momentum(float)-动量因子\n",
        "\n",
        "weight_decay(float):权重衰减,使用的目的是防止过拟合.在损失函数中,weight decay是放在正则项前面的一个系数,正则项一般指示模型的复杂度\n",
        "所以weight decay的作用是调节模型复杂度对损失函数的影响,若weight decay很大,则复杂的模型损失函数的值也就大.\n",
        "\n",
        "dampening:动量的有抑制因子\n",
        "\n",
        "optimizer.param_group:是长度为2的list,其中的元素是两个字典\n",
        "optimzer.param_group:长度为6的字典,包括['amsgrad','params','lr','weight_decay',eps']\n",
        "optimzer.param_group:表示优化器状态的一个字典\n",
        "\n",
        "'''\n",
        "optimizer=optim.SGD(model.parameters(),lr=lr,momentum=0.8,weight_decay=0.001) #神经网络优化器\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "scheduler 调整学习率而设置，我这里设置的gamma衰减率为0.5，step_size为10，也就是每10个epoch将学习率衰减至原来的0.5倍。\n",
        "optimizer(Optimizer):要更改学习率的优化器\n",
        "milestones(list):递增的list,存放要更新的lr的epoch\n",
        "gamma:(float):更新lr的乘法因子\n",
        "last_epoch:：最后一个epoch的index，如果是训练了很多个epoch后中断了，继续训练，这个值就等于加载的模型的epoch。\n",
        "默认为-1表示从头开始训练，即从epoch=1\n",
        "'''\n",
        "schedule=optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=0.5,last_epoch=-1)\n",
        "\n",
        "\n",
        "\n",
        "#训练\n",
        "loss_list=[]  #为了后续画出损失图\n",
        "start=time.time()\n",
        "\n",
        "#train\n",
        "for epoch in range(epoch_num):\n",
        "    ww = 0\n",
        "    running_loss=0.0\n",
        "    #0是对i的给值(循环次数从0开始计数还是从1开始计数的问题):\n",
        "    #???\n",
        "    for i,(inputs,labels) in enumerate(train_loader,0):\n",
        "\n",
        "        #将数据从train_loader中读出来,一次读取的样本是32个\n",
        "        inputs,labels=inputs.to(device),labels.to(device)\n",
        "\n",
        "        #用于梯度清零,在每次应用新的梯度时,要把原来的梯度清零,否则梯度会累加\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "\n",
        "        loss=criterion(outputs,labels).to(device)\n",
        "\n",
        "        #反向传播,pytorch会自动计算反向传播的值\n",
        "        loss.backward()\n",
        "        #对反向传播以后对目标函数进行优化\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss+=loss.item()\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        if(i+1)%num_print==0:\n",
        "            print('[%d epoch,%d]  loss:%.6f' %(epoch+1,i+1,running_loss/num_print))\n",
        "            running_loss=0.0\n",
        "\n",
        "    lr_1=optimizer.param_groups[0]['lr'] #返回优化器的第一个参数组的学习率\n",
        "    print(\"learn_rate:%.15f\"%lr_1)\n",
        "    schedule.step() #10 per epoch\n",
        "\n",
        "end=time.time()\n",
        "print(\"time:{}\".format(end-start))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#测试\n",
        "\n",
        "#由于训练集不需要梯度更新,于是进入测试模式\n",
        "model.eval()\n",
        "correct=0.0\n",
        "total=0\n",
        "with torch.no_grad(): #训练集不需要反向传播\n",
        "    print(\"=======================test=======================\")\n",
        "    for inputs,labels in test_loader:\n",
        "        inputs,labels=inputs.to(device),labels.to(device)\n",
        "        outputs=model(inputs)\n",
        "\n",
        "        pred=outputs.argmax(dim=1)  #返回每一行中最大值元素索引\n",
        "        total+=inputs.size(0)    #输入张量的第一维度的大小\n",
        "        correct+=torch.eq(pred,labels).sum().item() #sum()返回张量中所有元素的总和，item()返回标量张量的值\n",
        "\n",
        "print(\"Accuracy of the network on the 10000 test images:%.2f %%\" %(100*correct/total) )\n",
        "print(\"===============================================\")\n",
        "\n",
        "# # PATH = './content/drive/MyDrive/Colab Notebooks/model'  \n",
        "PATH = '/content/drive/MyDrive/ColabNotebooks/modelSave/ResNet34'\n",
        "# torch.save(model.state_dict(), PATH)\n",
        "torch.save({\n",
        "       'epoch': epoch,\n",
        "       'model_state_dict': model.state_dict(),\n",
        "       'optimizer_state_dict': optimizer.state_dict(),\n",
        "       'loss': loss,\n",
        "      \n",
        "      }, PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc2sKMTatCs7",
        "outputId": "914de2d1-a408-43d9-e4a1-0299eda1b075"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data_hub/cifar10/data_1/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12962754.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data_hub/cifar10/data_1/cifar-10-python.tar.gz to ../../data_hub/cifar10/data_1\n",
            "Files already downloaded and verified\n",
            "[1 epoch,100]  loss:1.986396\n",
            "learn_rate:0.010000000000000\n",
            "[2 epoch,100]  loss:1.377919\n",
            "learn_rate:0.010000000000000\n",
            "[3 epoch,100]  loss:1.180463\n",
            "learn_rate:0.010000000000000\n",
            "[4 epoch,100]  loss:1.042457\n",
            "learn_rate:0.010000000000000\n",
            "[5 epoch,100]  loss:0.929018\n",
            "learn_rate:0.010000000000000\n",
            "[6 epoch,100]  loss:0.841195\n",
            "learn_rate:0.010000000000000\n",
            "[7 epoch,100]  loss:0.757213\n",
            "learn_rate:0.010000000000000\n",
            "[8 epoch,100]  loss:0.696968\n",
            "learn_rate:0.010000000000000\n",
            "[9 epoch,100]  loss:0.633942\n",
            "learn_rate:0.010000000000000\n",
            "[10 epoch,100]  loss:0.574235\n",
            "learn_rate:0.010000000000000\n",
            "[11 epoch,100]  loss:0.449523\n",
            "learn_rate:0.005000000000000\n",
            "[12 epoch,100]  loss:0.367346\n",
            "learn_rate:0.005000000000000\n",
            "[13 epoch,100]  loss:0.316708\n",
            "learn_rate:0.005000000000000\n",
            "[14 epoch,100]  loss:0.287442\n",
            "learn_rate:0.005000000000000\n",
            "[15 epoch,100]  loss:0.254513\n",
            "learn_rate:0.005000000000000\n",
            "[16 epoch,100]  loss:0.240061\n",
            "learn_rate:0.005000000000000\n",
            "[17 epoch,100]  loss:0.216981\n",
            "learn_rate:0.005000000000000\n",
            "[18 epoch,100]  loss:0.199735\n",
            "learn_rate:0.005000000000000\n",
            "[19 epoch,100]  loss:0.184522\n",
            "learn_rate:0.005000000000000\n",
            "[20 epoch,100]  loss:0.178005\n",
            "learn_rate:0.005000000000000\n",
            "[21 epoch,100]  loss:0.110794\n",
            "learn_rate:0.002500000000000\n",
            "[22 epoch,100]  loss:0.058208\n",
            "learn_rate:0.002500000000000\n",
            "[23 epoch,100]  loss:0.042699\n",
            "learn_rate:0.002500000000000\n",
            "[24 epoch,100]  loss:0.032792\n",
            "learn_rate:0.002500000000000\n",
            "[25 epoch,100]  loss:0.026553\n",
            "learn_rate:0.002500000000000\n",
            "[26 epoch,100]  loss:0.017514\n",
            "learn_rate:0.002500000000000\n",
            "[27 epoch,100]  loss:0.016174\n",
            "learn_rate:0.002500000000000\n",
            "[28 epoch,100]  loss:0.010840\n",
            "learn_rate:0.002500000000000\n",
            "[29 epoch,100]  loss:0.008930\n",
            "learn_rate:0.002500000000000\n",
            "[30 epoch,100]  loss:0.009288\n",
            "learn_rate:0.002500000000000\n",
            "[31 epoch,100]  loss:0.005999\n",
            "learn_rate:0.001250000000000\n",
            "[32 epoch,100]  loss:0.005519\n",
            "learn_rate:0.001250000000000\n",
            "[33 epoch,100]  loss:0.003596\n",
            "learn_rate:0.001250000000000\n",
            "[34 epoch,100]  loss:0.003170\n",
            "learn_rate:0.001250000000000\n",
            "[35 epoch,100]  loss:0.002741\n",
            "learn_rate:0.001250000000000\n",
            "[36 epoch,100]  loss:0.002789\n",
            "learn_rate:0.001250000000000\n",
            "[37 epoch,100]  loss:0.002646\n",
            "learn_rate:0.001250000000000\n",
            "[38 epoch,100]  loss:0.002010\n",
            "learn_rate:0.001250000000000\n",
            "[39 epoch,100]  loss:0.002613\n",
            "learn_rate:0.001250000000000\n",
            "[40 epoch,100]  loss:0.002247\n",
            "learn_rate:0.001250000000000\n",
            "[41 epoch,100]  loss:0.001985\n",
            "learn_rate:0.000625000000000\n",
            "[42 epoch,100]  loss:0.001683\n",
            "learn_rate:0.000625000000000\n",
            "[43 epoch,100]  loss:0.001752\n",
            "learn_rate:0.000625000000000\n",
            "[44 epoch,100]  loss:0.001685\n",
            "learn_rate:0.000625000000000\n",
            "[45 epoch,100]  loss:0.001758\n",
            "learn_rate:0.000625000000000\n",
            "[46 epoch,100]  loss:0.001487\n",
            "learn_rate:0.000625000000000\n",
            "[47 epoch,100]  loss:0.001563\n",
            "learn_rate:0.000625000000000\n",
            "[48 epoch,100]  loss:0.001610\n",
            "learn_rate:0.000625000000000\n",
            "[49 epoch,100]  loss:0.001409\n",
            "learn_rate:0.000625000000000\n",
            "[50 epoch,100]  loss:0.001439\n",
            "learn_rate:0.000625000000000\n",
            "[51 epoch,100]  loss:0.001312\n",
            "learn_rate:0.000312500000000\n",
            "[52 epoch,100]  loss:0.001402\n",
            "learn_rate:0.000312500000000\n",
            "[53 epoch,100]  loss:0.001447\n",
            "learn_rate:0.000312500000000\n",
            "[54 epoch,100]  loss:0.001233\n",
            "learn_rate:0.000312500000000\n",
            "[55 epoch,100]  loss:0.001257\n",
            "learn_rate:0.000312500000000\n",
            "[56 epoch,100]  loss:0.001311\n",
            "learn_rate:0.000312500000000\n",
            "[57 epoch,100]  loss:0.001257\n",
            "learn_rate:0.000312500000000\n",
            "[58 epoch,100]  loss:0.001266\n",
            "learn_rate:0.000312500000000\n",
            "[59 epoch,100]  loss:0.001183\n",
            "learn_rate:0.000312500000000\n",
            "[60 epoch,100]  loss:0.001104\n",
            "learn_rate:0.000312500000000\n",
            "[61 epoch,100]  loss:0.001175\n",
            "learn_rate:0.000156250000000\n",
            "[62 epoch,100]  loss:0.001187\n",
            "learn_rate:0.000156250000000\n",
            "[63 epoch,100]  loss:0.001228\n",
            "learn_rate:0.000156250000000\n",
            "[64 epoch,100]  loss:0.001208\n",
            "learn_rate:0.000156250000000\n",
            "[65 epoch,100]  loss:0.001236\n",
            "learn_rate:0.000156250000000\n",
            "[66 epoch,100]  loss:0.001119\n",
            "learn_rate:0.000156250000000\n",
            "[67 epoch,100]  loss:0.001225\n",
            "learn_rate:0.000156250000000\n",
            "[68 epoch,100]  loss:0.001138\n",
            "learn_rate:0.000156250000000\n",
            "[69 epoch,100]  loss:0.001132\n",
            "learn_rate:0.000156250000000\n",
            "[70 epoch,100]  loss:0.001097\n",
            "learn_rate:0.000156250000000\n",
            "time:1908.5356271266937\n",
            "=======================test=======================\n",
            "Accuracy of the network on the 10000 test images:72.03 %\n",
            "===============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  CIFAR10+ResNet50 训练\n",
        "#  因为使用的分类场景大概率与resnet50的分类数不一样，\n",
        "#  所以在调用时，使用out_features=分类数进行调整。\n",
        "#  假设我们采用CIFAR10数据集（10 class）进行测试，\n",
        "#  那么我们就需要修改全连接层，out_features=10。\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        " \n",
        "#下载CIFAR10数据集\n",
        "# train_dataset=datasets.CIFAR10(root='../../data_hub/cifar10/data_1',train=True,transform=transform_train,download=True)\n",
        "# test_dataset=datasets.CIFAR10(root='../../data_hub/cifar10/data_1',train=False,transform=transform,download=True)\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"../../data_hub/cifar10/data_1\",\n",
        "                        train=True,\n",
        "                        transform=torchvision.transforms.ToTensor(),\n",
        "                        download=False)\n",
        "test_data = torchvision.datasets.CIFAR10(root=\"../../data_hub/cifar10/data_1\",\n",
        "                       train=False,\n",
        "                       transform=torchvision.transforms.ToTensor(),\n",
        "                       download=False)\n",
        "\n",
        "train_data_size = len(train_data)\n",
        "test_data_size = len(test_data)\n",
        "print(\"The size of Train_data is {}\".format(train_data_size))\n",
        "print(\"The size of Test_data is {}\".format(test_data_size))\n",
        " \n",
        "#dataloder进行数据集的加载\n",
        "train_dataloader = DataLoader(train_data,batch_size=128)\n",
        "test_dataloader = DataLoader(test_data,batch_size=128)\n",
        " \n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "num_ftrs = resnet50.fc.in_features\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False #False：冻结模型的参数，\n",
        "                                # 也就是采用该模型已经训练好的原始参数。\n",
        "                                #只需要训练我们自己定义的Linear层\n",
        "resnet50.fc = nn.Sequential(nn.Linear(num_ftrs,10),\n",
        "                            nn.LogSoftmax(dim=1))\n",
        " \n",
        "# 网络模型cuda\n",
        "if torch.cuda.is_available():\n",
        "    resnet50 = resnet50.cuda()\n",
        " \n",
        "#loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "    loss_fn = loss_fn.cuda()\n",
        "#optimizer\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(resnet50.parameters(),lr=learning_rate,)\n",
        " \n",
        "#设置网络训练的一些参数\n",
        "total_train_step = 0 #记录训练的次数\n",
        "total_test_step = 0  #记录测试的次数\n",
        "epoch = 50       #训练的轮数\n",
        " \n",
        "for i in range(epoch):\n",
        "    print(\"-------第{}轮训练开始-------\".format(i+1))\n",
        "    resnet50.train()\n",
        "    #训练步骤开始\n",
        "    for data in train_dataloader:\n",
        "        imgs, targets = data\n",
        "        if torch.cuda.is_available():\n",
        "            # 图像cuda；标签cuda\n",
        "            # 训练集和测试集都要有\n",
        "            imgs = imgs.cuda()\n",
        "            targets = targets.cuda()\n",
        "        outputs = resnet50(imgs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        " \n",
        "        # 优化器优化模型\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        " \n",
        "        total_train_step = total_train_step + 1\n",
        "        if total_train_step % 100 == 0:\n",
        "            print(\"训练次数：{}, Loss: {}\".format(total_train_step, loss.item()))\n",
        "            #writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
        "\n",
        "    #测试集\n",
        "    total_test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader:\n",
        "            imgs, targets = data\n",
        "            if torch.cuda.is_available():\n",
        "                # 图像cuda；标签cuda\n",
        "                # 训练集和测试集都要有\n",
        "                imgs = imgs.cuda()\n",
        "                targets = targets.cuda()\n",
        "            outputs = resnet50(imgs)\n",
        "            loss = loss_fn(outputs,targets)\n",
        "            total_test_loss += loss.item()\n",
        "            total_test_step += 1\n",
        "            if total_test_step % 100 ==0:\n",
        "                print(\"测试次数：{}，Loss：{}\".format(total_test_step,total_test_loss))   \n",
        "\n",
        "PATH = '/content/drive/MyDrive/ColabNotebooks/modelSave/ResNet50'\n",
        "# torch.save(model.state_dict(), PATH)\n",
        "torch.save({\n",
        "       'epoch': epoch,\n",
        "       'model_state_dict': model.state_dict(),\n",
        "       'optimizer_state_dict': optimizer.state_dict(),\n",
        "       'loss': loss,\n",
        "      \n",
        "      }, PATH)"
      ],
      "metadata": {
        "id": "KQWjige_D37x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}